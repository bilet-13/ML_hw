{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "import random\n",
    "feature_arr=['age','workclass','fnlwgt','education','education-num',\n",
    "            'marital-status','occupation','relationship','race','sex',\n",
    "            'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "input_type=['Id','age','workclass','fnlwgt','education','education-num',\n",
    "            'marital-status','occupation','relationship','race','sex',\n",
    "            'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "feature_continus_discrete_arr=['c','d','c','d','c','d','d','d','d','d','c','c','c','d']\n",
    "data_type=['Id','age','workclass','fnlwgt','education','education-num',\n",
    "            'marital-status','occupation','relationship','race','sex',\n",
    "            'capital-gain','capital-loss','hours-per-week','native-country',\n",
    "            'Category']\n",
    "\n",
    "continue_feature_threshold={'age':37,'fnlwgt':178233,'education-num':10,'capital-gain':0,'capital-loss':0,'hours-per-week':40}\n",
    "#判斷標準 中位數\n",
    "\n",
    "answer_arr=['Id','Category']\n",
    "class Node(object):\n",
    "    def __init__(self,attribute,threshold):\n",
    "        self.attr = attribute\n",
    "        self.thres = threshold\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.leaf = False\n",
    "        self.predict = None\n",
    "def trans_continue_to_bounding(data_arr,n):\n",
    "     for i in range(1,len(feature_arr)+1):\n",
    "        if feature_continus_discrete_arr[i-1]=='d':\n",
    "            continue\n",
    "        values=[int(row[i]) for row in data_arr]\n",
    "        values.sort()\n",
    "        size,rem=div_list_num(values,n)\n",
    "        start=0\n",
    "        end=size\n",
    "        for row in data_arr:\n",
    "            for j in range(n):\n",
    "                start=j*size\n",
    "                end=start+size-1\n",
    "                if j==(n-1):\n",
    "                    end+=rem\n",
    "                if int(row[i]) >= values[start] and  int(row[i]) <=values[end]:\n",
    "                    row[i]=str(j)\n",
    "                \n",
    "                    \n",
    "               \n",
    "                    \n",
    "\n",
    "\n",
    "def div_list_num(values,n):\n",
    "    size=0\n",
    "    size+=math.floor(len(values)/n)\n",
    "    rem=len(values)-size*n\n",
    "    while rem > n:\n",
    "        size+=math.floor(rem/n)\n",
    "        rem=len(values)-size*n\n",
    "    return size,rem\n",
    "\n",
    "\n",
    "def trans_string_to_codestring(data_arr):\n",
    "    for i in range(1,len(feature_arr)+1):\n",
    "        if feature_continus_discrete_arr[i-1]=='c':\n",
    "            continue\n",
    "        codedict={}\n",
    "        num=0\n",
    "        for row in range(len(data_arr)):\n",
    "            if data_arr[row][i] not in codedict.keys():\n",
    "                codedict[data_arr[row][i]]=num\n",
    "                num+=1\n",
    "            data_arr[row][i]=str(codedict[data_arr[row][i]])\n",
    "    \n",
    "def compute_entropy(data_arr):\n",
    "    arr_len=len(data_arr)\n",
    "    labelcount={}\n",
    "    for row in data_arr:\n",
    "        tmp_category=row[-1]\n",
    "        if tmp_category not in labelcount.keys():\n",
    "            labelcount[tmp_category]=0\n",
    "        labelcount[tmp_category]+=1\n",
    "    entro=0\n",
    "    #print(labelcount)\n",
    "    for key in labelcount:\n",
    "        pro=float(labelcount[key])/arr_len\n",
    "        entro -=pro*math.log(pro,2)\n",
    "    return entro\n",
    "def find_most_category(classlist):\n",
    "    classcount={}\n",
    "    for vote in classlist:\n",
    "        if vote not in classcount.keys():\n",
    "            classcount[vote]=0\n",
    "        classcount[vote]+=1\n",
    "    sortedlist= sorted(classcount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    #print(type(sortedlist))\n",
    "    return sortedlist[0][0]\n",
    "def choose_thres(data_arr,attribute):\n",
    "    if(feature_continus_discrete_arr[attribute-1]=='d'):\n",
    "        values=[float(row[attribute]) for row in data_arr]\n",
    "        values=set(values)\n",
    "        values=list(values)\n",
    "        values.sort()\n",
    "        max_ig=float(\"-inf\")\n",
    "        thres_val=0\n",
    "        for i in range(0,len(values)-1):\n",
    "            thres=(values[i]+values[i+1])/2\n",
    "            ig=info_gain(data_arr,attribute,thres)\n",
    "            if ig>max_ig:\n",
    "                max_ig=ig\n",
    "                thres_val=thres\n",
    "        return thres_val\n",
    "    else:\n",
    "        values=[float(row[attribute]) for row in data_arr]\n",
    "        return np.median(values)\n",
    "\n",
    "def info_gain(data_arr,attr,threshold):\n",
    "    sub1=[row for row in data_arr if float(row[attr])<=threshold]\n",
    "    #print(\"sub1len:\",len(sub1))\n",
    "    sub2=[row for row in data_arr if float(row[attr])>threshold]\n",
    "    #print(\"sub2len:\",len(sub2))\n",
    "    ig=compute_entropy(data_arr)-remainder(data_arr,[sub1 ,sub2])\n",
    "    return ig\n",
    "\n",
    "def remainder(data_arr,data_subsets):\n",
    "        num=len(data_arr)\n",
    "        rem=float(0)\n",
    "        for sub in data_subsets:\n",
    "            rem += float(len(sub)/num)*compute_entropy(sub)\n",
    "        return rem\n",
    "def choose_attr(data_arr):\n",
    "    max_info_gain=float('-inf')\n",
    "    best_attr=None\n",
    "    threshold=0\n",
    "    for attr in range(1,len(feature_arr)+1 ):\n",
    "        thres=choose_thres(data_arr,attr)\n",
    "    ig = info_gain(data_arr,attr,thres)\n",
    "    if ig > max_info_gain:\n",
    "        max_info_gain=ig\n",
    "        best_attr=attr\n",
    "        threshold=thres\n",
    "    return best_attr,threshold\n",
    "def create_tree(data_arr):\n",
    "    #print(\"now arrlen:\",len(data_arr))\n",
    "    classlist=[row[-1] for row in data_arr]\n",
    "    if classlist.count(classlist[0])==len(classlist):\n",
    "        leaf = Node(None,None)\n",
    "        leaf.leaf=True\n",
    "        leaf.predict=classlist[0]\n",
    "        return leaf\n",
    "    best_attr,threshold = choose_attr(data_arr)\n",
    "    attrlist=[row[best_attr] for row in data_arr ]\n",
    "    if attrlist.count(attrlist[0])==len(attrlist):\n",
    "        leaf = Node(None,None)\n",
    "        leaf.leaf=True\n",
    "        f=classlist.count('0')\n",
    "        t=classlist.count('1')\n",
    "        if t>f:\n",
    "            leaf.predict='1'\n",
    "        else:\n",
    "            leaf.predict='0'\n",
    "        return leaf\n",
    "    #print(\"choose success\")\n",
    "    tree=Node(best_attr,threshold)\n",
    "    sub1=[row for row in data_arr if float(row[best_attr]) <= threshold]\n",
    "    sub2=[row for row in data_arr if float(row[best_attr]) > threshold]\n",
    "    #print(\"sub1len:\",len(sub1))\n",
    "    #print(\"sub2len:\",len(sub2))\n",
    "    #print(\"attribute:\",feature_arr[best_attr-1],'threshold:',threshold)\n",
    "    tree.left = create_tree(sub1)\n",
    "    tree.right = create_tree(sub2)\n",
    "    return tree\n",
    "def printtree(root,level):\n",
    "    if root.leaf:\n",
    "        print(\"root.predict:\",root.predict)\n",
    "    else:\n",
    "        print(\"attr:\",feature_arr[root.attr-1],\"threshold:\",root.thres)\n",
    "    if root.left:\n",
    "        printtree(root.left,level+1)\n",
    "    if root.right:\n",
    "        printtree(root.right,level+1)\n",
    "def predict(node,row_data,time):\n",
    "    if node.leaf:\n",
    "        if time<=10:\n",
    "            print(\"in the leaf the prediction is:\",node.predict)\n",
    "        return node.predict\n",
    "    if float(row_data[node.attr]) <= node.thres:\n",
    "        if time<=10:\n",
    "            print(\"attribe:\",feature_arr[node.attr-1],\"the value<=thres\",node.thres,\"go to left node\")\n",
    "        return predict(node.left,row_data,time)\n",
    "    elif float(row_data[node.attr]) > node.thres:\n",
    "        if time<=10:\n",
    "            print(\"attribe:\",feature_arr[node.attr-1],\"the value>=thres\",node.thres,\"go to right node\")\n",
    "        return predict(node.right,row_data,time)\n",
    "def print_result(tp,fp,fn,tn):\n",
    "    print(\"confusion matrix\\ntrue positive:\",tp,' false positive:',fp,\n",
    "    \"\\nfalse negative:\",fn,'true negative:',tn)\n",
    "    print('Accuracy:',(tp+tn)/(tp+tn+fp+fn))\n",
    "    print('Precision:',tp/(tp+fp))\n",
    "    print('Recall:',tp/(tp+fn))\n",
    "    \n",
    "def predict_and_handle_result(root,test_arr):\n",
    "    tp=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    tn=0\n",
    "    time=0\n",
    "    for row in test_arr:\n",
    "        time+=1\n",
    "        result=predict(root,row,time)\n",
    "        if result == row[-1] and result=='0':\n",
    "            tp+=1\n",
    "        elif result == row[-1] and result=='1':\n",
    "            tn+=1\n",
    "        elif result != row[-1] and result=='1':\n",
    "            fn+=1\n",
    "        elif result != row[-1] and result=='0':\n",
    "            fp+=1\n",
    "    return tp,fp,fn,tn\n",
    "def create_forest(data_arr,quantity,sub_data_size):\n",
    "    forest=[]\n",
    "    for i in range(quantity):\n",
    "        sub_arr=random.sample(data_arr,sub_data_size)\n",
    "        forest.append(create_tree(sub_arr))\n",
    "    return forest\n",
    "def forest_predict(forest,row):\n",
    "    p=0\n",
    "    n=0\n",
    "    for tree in forest:\n",
    "        result=predict(tree,row,20)\n",
    "        if result=='0':\n",
    "            p+=1\n",
    "        elif result=='1':\n",
    "            n+=1\n",
    "    if p>n:\n",
    "        return '0'\n",
    "    else:\n",
    "        return '1'\n",
    "        \n",
    "def handle_forest_predict(forest,test_arr):\n",
    "    tp=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    tn=0\n",
    "    for row in test_arr:\n",
    "        result=forest_predict(forest,row)\n",
    "        if result == row[-1] and result=='0':\n",
    "            tp+=1\n",
    "        elif result == row[-1] and result=='1':\n",
    "            tn+=1\n",
    "        elif result != row[-1] and result=='1':\n",
    "            fn+=1\n",
    "        elif result != row[-1] and result=='0':\n",
    "            fp+=1\n",
    "    return tp,fp,fn,tn  \n",
    "\n",
    "\n",
    "\n",
    "fp=open('X_train.csv','r',newline='')\n",
    "xtestdict=csv.DictReader(fp)\n",
    "f=open('Y_train.csv','r',newline='')\n",
    "ytestdict=csv.DictReader(f)\n",
    "#create 2d array ,include feature and outcome\n",
    "data_arr=[]\n",
    "row_len=0\n",
    "#******\n",
    "for row in xtestdict:\n",
    "    data_arr.append([])\n",
    "    for i in range(len(input_type)):\n",
    "        data_arr[row_len].append(row[input_type[i]])\n",
    "    row_len+=1\n",
    "row_len=0\n",
    "for row in ytestdict:\n",
    "    data_arr[row_len].append(row[data_type[-1]]) #add category\n",
    "    row_len+=1\n",
    "f.close()\n",
    "fp.close()\n",
    "#**************************************\n",
    "#data preprocessing staryt!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "#shuffle data\n",
    "np.random.shuffle(data_arr)\n",
    "\n",
    "#delete miss value\n",
    "arr_len=0\n",
    "while arr_len<len(data_arr):\n",
    "    a=0\n",
    "    a=data_arr[arr_len].count(' ?')\n",
    "    arr_len+=1\n",
    "    if a>0:\n",
    "        arr_len-=1\n",
    "        del data_arr[arr_len]\n",
    "\n",
    "#modified discrete data\n",
    "trans_string_to_codestring(data_arr)\n",
    "\n",
    "#modified continue date\n",
    "trans_continue_to_bounding(data_arr,15)\n",
    "filep=open('X_test.csv','r',newline='')\n",
    "xtest=csv.DictReader(filep)\n",
    "#create 2d array ,include feature and outcome\n",
    "test_data_arr=[]\n",
    "row_len=0\n",
    "#******\n",
    "for row in xtest:\n",
    "    test_data_arr.append([])\n",
    "    for i in range(len(input_type)):\n",
    "        test_data_arr[row_len].append(row[input_type[i]])\n",
    "    row_len+=1\n",
    "row_len=0\n",
    "wfp=open('Y_test.csv','w',newline='')\n",
    "writer=csv.writer(wfp)\n",
    "writer.writerow(['Id','Category'])\n",
    "\n",
    "#modified discrete data\n",
    "trans_string_to_codestring(test_data_arr)\n",
    "\n",
    "#modified continue date\n",
    "trans_continue_to_bounding(test_data_arr,15)\n",
    "time=20\n",
    "pre_root=create_tree(data_arr)\n",
    "for row in test_data_arr:\n",
    "    #print(row[0])\n",
    "    result=predict(pre_root,row,time)\n",
    "    writer.writerow([row[0],result])\n",
    "wfp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
